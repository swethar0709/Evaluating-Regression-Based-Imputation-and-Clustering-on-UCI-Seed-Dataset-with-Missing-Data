{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7431be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Incomplete Data imputation for effective Seed Data clustering. Using again the UCI seed dataset (without the label),\n",
    "randomly delete 1 or 2 feature values in each data item. Then implement a regression approach (either a modified\n",
    "K-NN regression or a modified locally weighted linear regression) to impute (predict) the values for the missing attributes\n",
    "before applying clustering to the completed data to see how well the resulting clusters still represent the labels.\n",
    "Evaluate how well your regressor can predict the missing values and how similar the resulting clusters are to clusters \n",
    "obtained on the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7e2382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for imputed values: 1.5011\n",
      "Silhouette score for the original dataset: 0.61\n",
      "Silhouette score for the imputed dataset: 0.55\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt\"\n",
    "    data = np.loadtxt(url)\n",
    "    return data[:, :-1], data[:, -1]\n",
    "\n",
    "\n",
    "def remove_random_values(X, random_state=52):\n",
    "    random.seed(random_state)\n",
    "    for row in X:\n",
    "        indices_to_remove = random.sample(range(7), random.randint(1, 2))\n",
    "        for index in indices_to_remove:\n",
    "            row[index] = np.nan\n",
    "    return X\n",
    "\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    valid_indices = ~np.isnan(x1) & ~np.isnan(x2)\n",
    "    return np.sqrt(np.sum((x1[valid_indices] - x2[valid_indices]) ** 2))\n",
    "\n",
    "\n",
    "\n",
    "def cdist(X, centroids, metric='euclidean'):\n",
    "    distances = []\n",
    "    for x in X:\n",
    "        row = []\n",
    "        for centroid in centroids:\n",
    "            row.append(euclidean_distance(x, centroid))\n",
    "        distances.append(row)\n",
    "    return np.array(distances)\n",
    "\n",
    "\n",
    "def knn_impute(X, missing_val, n_neighbors=5):\n",
    "    X_imputed = X.copy()\n",
    "    n = X.shape[0]\n",
    "    col_means = np.nanmean(X, axis=0)  # Compute column means\n",
    "    for i in range(n):\n",
    "        if missing_val[i].any():\n",
    "            valid_samples = [j for j in range(n) if i != j and not np.any(missing_val[j])]\n",
    "            if len(valid_samples) == 0:  # If no valid samples\n",
    "#                 print(f\"No valid samples found for instance {i}. Imputing with column mean.\")\n",
    "                X_imputed[i, missing_val[i]] = col_means[missing_val[i]]\n",
    "                continue\n",
    "            distances = np.array([euclidean_distance(X[i], X[j]) for j in valid_samples])\n",
    "            nearest_indices = np.argsort(distances)[:n_neighbors]\n",
    "            nearest_values = X[valid_samples][nearest_indices][:, ~missing_val[i]]\n",
    "            if nearest_values.size == 0:  # If no nearest_values\n",
    "                print(f\"No nearest neighbors found for instance {i}. Imputing with column mean.\")\n",
    "                X_imputed[i, missing_val[i]] = col_means[missing_val[i]]\n",
    "                continue\n",
    "            missing_values = np.nanmean(nearest_values, axis=0)\n",
    "            X_imputed[i, missing_val[i]] = missing_values[:np.sum(missing_val[i])]\n",
    "    return X_imputed\n",
    "\n",
    "\n",
    "\n",
    "def kmeans_clustering(X, n_clusters=3, random_state=42, max_iter=300):\n",
    "    np.random.seed(random_state)\n",
    "    centroids = X[np.random.choice(X.shape[0], n_clusters, replace=False)]\n",
    "    for _ in range(max_iter):\n",
    "        distances = cdist(X, centroids, metric='euclidean')\n",
    "        cluster_labels = np.argmin(distances, axis=1)\n",
    "        new_centroids = np.array([np.nanmean(X[cluster_labels == i], axis=0) for i in range(n_clusters)])\n",
    "        if np.all(np.isnan(new_centroids)):\n",
    "            break  # Break if all new centroids are NaN\n",
    "        elif np.allclose(centroids, new_centroids, atol=1e-4):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    return cluster_labels\n",
    "\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    missing_indices = np.isnan(y_true)\n",
    "    if np.any(missing_indices):\n",
    "        print(\"Warning: Missing values found in y_true. Cannot compute MSE.\")\n",
    "        return np.nan\n",
    "    squared_diff = (y_true[~missing_indices] - y_pred[~missing_indices]) ** 2\n",
    "    mse = np.mean(squared_diff)\n",
    "    return mse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def silhouette_score(X, labels):\n",
    "    if np.any(np.isnan(X)):\n",
    "        print(\"Warning: Missing values found in X. Cannot compute silhouette score.\")\n",
    "        return np.nan\n",
    "    distances = cdist(X, X, metric='euclidean')\n",
    "    n = X.shape[0]\n",
    "    A = np.array([np.nanmean(distances[i, labels == labels[i]]) for i in range(n)])\n",
    "    B = np.array([np.nanmean(distances[i, labels != labels[i]], axis=0) if np.any(labels != labels[i]) else np.nan for i in range(n)])\n",
    "    silhouette = np.nanmean((B - A) / np.maximum(A, B))\n",
    "    return silhouette\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X, y = load_data()\n",
    "X_incomplete = remove_random_values(X.copy(), random_state=52)\n",
    "\n",
    "missing_val = np.isnan(X_incomplete)\n",
    "\n",
    "X_imputed = knn_impute(X_incomplete, missing_val)\n",
    "\n",
    "mse = mean_squared_error(X[missing_val], X_imputed[missing_val])\n",
    "print(f\"Mean Squared Error for imputed values: {mse:.4f}\")\n",
    "\n",
    "\n",
    "labels_original = kmeans_clustering(X)\n",
    "labels_imputed = kmeans_clustering(X_imputed)\n",
    "\n",
    "\n",
    "silhouette_original = silhouette_score(X, labels_original) \n",
    "silhouette_imputed = silhouette_score(X_imputed, labels_imputed)\n",
    "\n",
    "print(f\"Silhouette score for the original dataset: {silhouette_original:.2f}\")\n",
    "print(f\"Silhouette score for the imputed dataset: {silhouette_imputed:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b84b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
